#!/usr/bin/env -S uv --quiet run --script
# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "pydub>=0.25.1",
#     "typer>=0.9.0",
#     "rich>=13.7.0",
#     "demucs>=0.1.0",
#     "requests>=2.28.1",
# ]
# ///

from pathlib import Path
from typing import Optional
import math
import os
import subprocess
import sys
import requests
import tempfile

from pydub import AudioSegment
from pydub.silence import detect_leading_silence
import typer
from rich import print

def format_duration(ms: float) -> str:
    """Format milliseconds as HH:MM:SS.ss"""
    total_seconds = ms / 1000
    hours = math.floor(total_seconds / 3600)
    minutes = math.floor((total_seconds % 3600) / 60)
    seconds = total_seconds % 60
    if hours > 0:
        return f"{hours}:{minutes:02d}:{seconds:05.2f}"
    else:
        return f"{minutes}:{seconds:05.2f}"

def format_size(size_in_bytes: int) -> str:
    """Format file size in bytes to human readable format."""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_in_bytes < 1024.0:
            return f"{size_in_bytes:.1f}{unit}"
        size_in_bytes /= 1024.0
    return f"{size_in_bytes:.1f}TB"

def isolate_voice_elevenlabs(input_path: Path, api_key: str, debug: bool = False, quiet: bool = False) -> Path:
    """Isolate voice using Eleven Labs API."""
    if not quiet:
        print("Isolating voice using Eleven Labs API...")
    
    # API endpoint
    url = "https://api.elevenlabs.io/v1/audio-isolation/isolate-speech"
    headers = {
        "Accept": "application/json",
        "xi-api-key": api_key
    }

    # Create a temporary file for the output
    output_path = input_path.parent / f"{input_path.stem}_vocals_temp.wav"
    
    try:
        with open(input_path, 'rb') as f:
            files = {'audio': f}
            response = requests.post(url, headers=headers, files=files)
            response.raise_for_status()
            
            # Save the isolated voice
            with open(output_path, 'wb') as f:
                f.write(response.content)
        
        if not quiet:
            print("[green]✓[/green] Voice isolation complete")
        return output_path
        
    except requests.exceptions.RequestException as e:
        if debug:
            print(f"[red]Error:[/red] Eleven Labs API request failed: {str(e)}")
        raise

def isolate_voice_demucs(input_path: Path, debug: bool = False, quiet: bool = False) -> Path:
    """Isolate voice from audio using Demucs (fallback method)."""
    try:
        import torch
        from demucs.apply import apply_model
        from demucs.pretrained import get_model
        from demucs.audio import AudioFile, save_audio
    except ImportError:
        print("[red]Error:[/red] Voice isolation requires additional dependencies.")
        print("Install them with: pip install demucs")
        raise typer.Exit(1)
    
    if not quiet:
        print("Isolating voice using Demucs (this may take a few minutes)...")
    
    # Load model
    model = get_model('htdemucs')
    model.cpu()
    model.eval()
    
    # Load audio
    wav = AudioFile(input_path).read(streams=0, samplerate=model.samplerate, channels=model.audio_channels)
    ref = wav.mean(0)
    wav = (wav - ref.mean()) / ref.std()
    
    # Apply model to get all stems
    with torch.no_grad():
        stems = apply_model(model, wav[None], split=True, device='cpu')[0]
        stems = stems * ref.std() + ref.mean()
    
    # Get the vocals track (index depends on model)
    sources = model.sources
    vocals_idx = sources.index('vocals')
    vocals = stems[vocals_idx]
    
    # Save to temporary file
    output_path = input_path.parent / f"{input_path.stem}_vocals_temp.wav"
    save_audio(vocals, str(output_path), model.samplerate)
    
    if not quiet:
        print("[green]✓[/green] Voice isolation complete")
    
    return output_path

def isolate_voice(input_path: Path, debug: bool = False, quiet: bool = False) -> Path:
    """Isolate voice from audio, using Eleven Labs if API key is available, falling back to Demucs."""
    api_key = os.getenv('ELEVENLABS_API_KEY')
    
    if api_key:
        try:
            return isolate_voice_elevenlabs(input_path, api_key, debug, quiet)
        except Exception as e:
            if not quiet:
                print(f"[yellow]Warning:[/yellow] Eleven Labs API failed: {str(e)}")
                print("Falling back to local processing with Demucs...")
            return isolate_voice_demucs(input_path, debug, quiet)
    else:
        if not quiet:
            print("[yellow]Note:[/yellow] ELEVENLABS_API_KEY not found, using local processing...")
        return isolate_voice_demucs(input_path, debug, quiet)

def trim_silence(
    input_path: Path,
    output_path: Optional[Path] = None,
    silence_threshold: int = -35,  # dB
    chunk_size: int = 100,  # ms
    format: Optional[str] = None,
    bitrate: Optional[str] = None,
    quality: Optional[int] = None,
    debug: bool = False,
    quiet: bool = False,
    isolate: bool = False,
) -> None:
    """Remove silence from the beginning and end of an audio file."""
    # Isolate voice if requested
    temp_file = None
    if isolate:
        try:
            temp_file = isolate_voice(input_path, debug, quiet)
            input_path = temp_file
        except Exception as e:
            if not quiet:
                print(f"[yellow]Warning:[/yellow] Voice isolation failed: {str(e)}")
                print("Proceeding with original audio...")
    
    try:
        # Load the audio file
        audio = AudioSegment.from_file(str(input_path))
        original_duration = len(audio)
        original_size = input_path.stat().st_size
        
        if debug and not quiet:
            print(f"[yellow]Debug:[/yellow] Processing with silence threshold: {silence_threshold}dB")
        
        # Trim silence using chunks for better performance
        def trim_silence_end(audio_segment):
            """Trim silence from the end of an audio segment."""
            total_trimmed = 0
            while audio_segment and len(audio_segment) > chunk_size:
                chunk_silence = detect_leading_silence(
                    audio_segment[-chunk_size:],
                    silence_threshold=silence_threshold
                )
                if chunk_silence < chunk_size:
                    break
                audio_segment = audio_segment[:-chunk_size]
                total_trimmed += chunk_size
                
            if audio_segment:
                # Fine-tune the last chunk
                silence_length = detect_leading_silence(
                    audio_segment.reverse(),
                    silence_threshold=silence_threshold
                )
                if silence_length > 0:
                    audio_segment = audio_segment[:-silence_length]
                    total_trimmed += silence_length
                    
            if debug and not quiet:
                print(f"[yellow]Debug:[/yellow] Trimmed {total_trimmed/1000:.2f}s from end")
            return audio_segment, total_trimmed
        
        # Trim start
        start_trimmed = 0
        while len(audio) > chunk_size:
            chunk_silence = detect_leading_silence(
                audio[:chunk_size],
                silence_threshold=silence_threshold
            )
            if chunk_silence < chunk_size:
                break
            audio = audio[chunk_size:]
            start_trimmed += chunk_size
        
        # Fine-tune the start
        start_trim = detect_leading_silence(audio, silence_threshold=silence_threshold)
        if start_trim > 0:
            audio = audio[start_trim:]
            start_trimmed += start_trim
        
        if debug and not quiet:
            print(f"[yellow]Debug:[/yellow] Trimmed {start_trimmed/1000:.2f}s from start")
        
        # Trim end
        audio, end_trimmed = trim_silence_end(audio)
        
        # Determine output path and format
        if output_path is None:
            # Use different separator based on whether original filename has spaces
            separator = " trimmed" if " " in input_path.stem else "_trimmed"
            stem = input_path.stem + separator
            if format is None:
                output_path = input_path.with_stem(stem)
            else:
                # Use the requested format's extension
                output_path = input_path.with_name(f"{stem}.{format}")
        
        if format is None:
            format = input_path.suffix.lstrip('.')
        
        # Convert m4a format to ipod for ffmpeg compatibility
        export_format = 'ipod' if format == 'm4a' else format
        
        # Export with optional parameters
        export_kwargs = {}
        if bitrate:
            export_kwargs['bitrate'] = bitrate
        if quality is not None:
            if format == 'ogg':
                export_kwargs['parameters'] = ["-q:a", str(quality)]
            else:
                export_kwargs['quality'] = quality
            
        audio.export(
            str(output_path),
            format=export_format,
            **export_kwargs
        )
        
        # Print results
        if not quiet:
            new_duration = len(audio)
            removed_duration = original_duration - new_duration
            new_size = output_path.stat().st_size
            size_change = new_size - original_size
            size_change_pct = (size_change / original_size) * 100
            
            print(f"[green]✓[/green] Successfully processed audio:")
            print(f"  • Original duration: {format_duration(original_duration)}")
            print(f"  • New duration: {format_duration(new_duration)}")
            print(f"  • Removed from start: {format_duration(start_trimmed)}")
            print(f"  • Removed from end: {format_duration(end_trimmed)}")
            print(f"  • Total silence removed: {format_duration(removed_duration)}")
            print(f"  • Original size: {format_size(original_size)}")
            print(f"  • New size: {format_size(new_size)}")
            print(f"  • Size change: {format_size(abs(size_change))} ({size_change_pct:+.1f}%)")
            print(f"  • Output saved to: {output_path}")
    finally:
        # Clean up temporary file
        if temp_file and temp_file.exists():
            temp_file.unlink()

def main(
    input_file: Path = typer.Argument(..., help="Input audio file"),
    output_file: Optional[Path] = typer.Option(None, "--output", "-o", help="Output file path"),
    threshold: int = typer.Option(-35, "--threshold", "-t", help="Silence threshold in dB"),
    chunk_size: int = typer.Option(100, "--chunk-size", "-c", help="Processing chunk size in ms"),
    format: Optional[str] = typer.Option(None, "--format", "-f", help="Output format (e.g., mp3, wav, ogg, m4a)"),
    bitrate: Optional[str] = typer.Option(None, "--bitrate", "-b", 
        help="Output bitrate (e.g., 128k, 192k, 256k, 320k). Common ranges:\n"
             "  • MP3: 32k-320k (common: 128k, 192k, 256k, 320k)\n"
             "  • AAC/M4A: 32k-400k (common: 128k, 256k)\n"
             "  • OGG: 45k-500k (common: 128k, 192k, 256k)\n"
             "  • WAV: not applicable (lossless)"),
    quality: Optional[int] = typer.Option(None, "--quality", "-q", 
        help="Output quality (format dependent):\n"
             "  • OGG: -1 (lowest) to 10 (highest), default ~3\n"
             "  • MP3: 0 (best) to 9 (worst), default 4\n"
             "  • M4A: 0 (worst) to 100 (best), default 80\n"
             "  • WAV: not applicable (lossless)"),
    debug: bool = typer.Option(False, "--debug", "-d", help="Show debug information"),
    quiet: bool = typer.Option(False, "--quiet", "-q", help="Suppress all output except errors"),
    isolate: bool = typer.Option(False, "--isolate", "-i", help="Isolate voice before processing (requires demucs or ELEVENLABS_API_KEY)"),
) -> None:
    """
    Remove silence from the beginning and end of an audio file.
    
    The script detects and removes silence below the specified threshold
    from both ends of the audio file.
    """
    if not input_file.exists():
        print(f"[red]Error:[/red] Input file '{input_file}' does not exist")
        raise typer.Exit(1)
        
    try:
        trim_silence(
            input_file,
            output_file,
            threshold,
            chunk_size,
            format,
            bitrate,
            quality,
            debug,
            quiet,
            isolate
        )
    except Exception as e:
        print(f"[red]Error:[/red] {str(e)}")
        raise typer.Exit(1)

if __name__ == "__main__":
    typer.run(main)
